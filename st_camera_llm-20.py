#from email.mime import image
#from re import L
#from httpx import stream
import streamlit as st
from streamlit_webrtc import webrtc_streamer, VideoTransformerBase, WebRtcMode
import cv2
import base64
import speech_recognition as sr
import pyttsx3

from langchain_core.prompts import ChatPromptTemplate
from langchain_core.output_parsers import StrOutputParser
from langchain_openai import ChatOpenAI
from langchain_anthropic import ChatAnthropic
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_cohere.chat_models import ChatCohere
from langchain_ollama import ChatOllama

import asyncio
import nest_asyncio
import threading
import keyboard
#from torch import res

r = sr.Recognizer()
engine = pyttsx3.init()
nest_asyncio.apply()

def init_page():
    st.set_page_config(
        page_title="My Chat",
        page_icon="ğŸ¤—"
    )
    st.header("My Chat ğŸ¤—")
    st.sidebar.title("Options")

def init_messages():
    clear_button = st.sidebar.button("Clear Conversation", key="clear")
    # clear_button ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã‚„ message_history ãŒã¾ã å­˜åœ¨ã—ãªã„å ´åˆã«åˆæœŸåŒ–
    if clear_button or "message_history" not in st.session_state:
        st.session_state.message_history = [
            ("system", "You are a helpful assistant.")
        ]    

def select_model():
    # ã‚¹ãƒ©ã‚¤ãƒ€ãƒ¼ã‚’è¿½åŠ ã—ã€temperatureã‚’0ã‹ã‚‰2ã¾ã§ã®ç¯„å›²ã§é¸æŠå¯èƒ½ã«ã™ã‚‹
    # åˆæœŸå€¤ã¯0.0ã€åˆ»ã¿å¹…ã¯0.01ã¨ã™ã‚‹
    temperature = st.sidebar.slider(
        "Temperature(å›ç­”ãƒãƒ©ãƒ„ã‚­åº¦åˆ):", min_value=0.0, max_value=2.0, value=0.0, step=0.01)
    models = ("llava-llama3","llava","llava-phi3", "GPT-4o", "Claude 3.5 Sonnet", "Gemini 1.5 Pro",
              "command-r-plus","mistral","llama3.1","aya","ELYZA-JP:8b")
    model = st.sidebar.radio("Choose a modelï¼ˆå¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«ã‚’é¸æŠï¼‰:", models)

    if model == "llava-llama3":
        st.session_state.model_name = "llava-llama3"
        return ChatOllama(
            temperature=temperature,
            #model_name=st.session_state.model_name,
            model=st.session_state.model_name
        )   #.bind(images=[base64_image])
    elif model == "llava":
        st.session_state.model_name = "llava"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        ) 
    elif model == "llava-phi3":
        st.session_state.model_name = "llava-phi3"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        )      
    elif model == "GPT-4o":  #"gpt-4o 'gpt-4o-2024-08-06'" æœ‰æ–™ï¼Ÿã€Best
        st.session_state.model_name = "gpt-4o"
        return ChatOpenAI(
            temperature=temperature,
            model=st.session_state.model_name,
            max_tokens=512,  #æŒ‡å®šã—ãªã„ã¨çŸ­ã„å›ç­”ã«ãªã£ãŸã‚Šã€é€”åˆ‡ã‚ŒãŸã‚Šã™ã‚‹ã€‚
            streaming=True,
        )
    elif model == "Claude 3.5 Sonnet": #ã‚³ãƒ¼ãƒ‰ãŒGoodï¼ï¼
        st.session_state.model_name = "claude-3-5-sonnet-20240620"
        return ChatAnthropic(
            temperature=temperature,
            #model=st.session_state.model_name,
            model_name=st.session_state.model_name,  
            max_tokens_to_sample=2048,  
            timeout=None,  
            max_retries=2,
            stop=None,  
        )
    elif model == "Gemini 1.5 Pro":
        st.session_state.model_name = "gemini-1.5-pro-latest"
        return ChatGoogleGenerativeAI(
            temperature=temperature,
            model=st.session_state.model_name
        )
    elif model == "command-r-plus":
        st.session_state.model_name = "command-r-plus"
        return ChatCohere(
            temperature=temperature,
            model=st.session_state.model_name,
            streaming=True,
        )
    elif model == "mistral":
        st.session_state.model_name = "mistral"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        )
    elif model == "llama3.2":
        st.session_state.model_name = "llama3.2"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        )
    elif model == "aya":
        st.session_state.model_name = "aya"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        )
    elif model == "ELYZA-JP:8b":
        st.session_state.model_name = "ELYZA-JP:8b"
        return ChatOllama(
            temperature=temperature,
            model=st.session_state.model_name
        )
    
#######################################################################
#  LLMå•ç­”é–¢æ•°   
async def query_llm(user_input,frame):
    print("user_input=",user_input)

    try:
            
        # ç”»åƒã‚’é©åˆ‡ãªå½¢å¼ã«å¤‰æ›ï¼ˆä¾‹ï¼šbase64ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰ãªã©ï¼‰
        # ç”»åƒã‚’ã‚¨ãƒ³ã‚³ãƒ¼ãƒ‰
        encoded_image = cv2.imencode('.jpg', frame)[1]
        # ç”»åƒã‚’Base64ã«å¤‰æ›
        base64_image = base64.b64encode(encoded_image).decode('utf-8')  
        #image = f"data:image/jpeg;base64,{base64_image}"
        
        if st.session_state.model_name ==  "keep_gpt-4o":
            llm = st.session_state.llm  
            stream = llm.stream([
                    *st.session_state.message_history,
                    (
                        "user",
                        [
                            {
                                "type": "text",
                                "text": user_input
                            },
                            {
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{base64_image}",
                                    "detail": "auto"
                                },
                            }
                        ]
                    )
                ])
            #response = chain.invoke(user_input)
            # LLMã®è¿”ç­”ã‚’è¡¨ç¤ºã™ã‚‹  Streaming
            with st.chat_message('ai'):   
                #st.write(response)  
                response = st.write_stream(stream) 
            #full = next(stream)
            #for chunk in stream:
                #full += chunk
            #response = full    
            print(response)
          
        
        if st.session_state.model_name ==  "command-r-plus":
            print("st.session_state.model_name=",st.session_state.model_name)
            print(user_input)
            prompt = ChatPromptTemplate.from_messages(
                [
                    *st.session_state.message_history,
                     #("user", f"{user_input}:{base64_image}"),  #ã‚„ã£ã±ã‚Šã ã‚
                     ("user", f"{user_input}")
                ]
            )
            
            output_parser = StrOutputParser()
            chain = prompt | st.session_state.llm | output_parser
            #stream = chain.stream(user_input,base64_image)
            
            stream = chain.stream({"user_input":user_input,"base64_image": base64_image})
            print("stream=",stream)
            #response = chain.invoke(user_input)
            # LLMã®è¿”ç­”ã‚’è¡¨ç¤ºã™ã‚‹  Streaming
            with st.chat_message('ai'):   
                #st.write(response)  
                response =st.write_stream(stream) 
            print("response=",response)

        elif st.session_state.model_name ==  "keep_command-r-plus":
            print("st.session_state.model_name=",st.session_state.model_name)
            prompt = ChatPromptTemplate.from_messages([
                    *st.session_state.message_history,
                    ("user", "{user_input}")  # ã“ã“ã«ã‚ã¨ã§ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®å…¥åŠ›ãŒå…¥ã‚‹
                ])
            output_parser = StrOutputParser()
            chain = prompt | st.session_state.llm | output_parser
            stream = chain.stream(user_input)
            
            #response = chain.invoke(user_input)
            # LLMã®è¿”ç­”ã‚’è¡¨ç¤ºã™ã‚‹  Streaming
            with st.chat_message('ai'):   
                #st.write(response)  
                response =st.write_stream(stream) 
            print("response=",response)
        else:
            print("st.session_state.model_name=",st.session_state.model_name)
            prompt = ChatPromptTemplate.from_messages(
                [
                    *st.session_state.message_history,
                    (
                        "user",
                        [
                            {
                                "type": "text",
                                "text": user_input
                            },
                            {
                                "type": "image_url",
                                "image_url": {"url": f"data:image/jpeg;base64,{base64_image}"},
                            }
                        ],
                    ),
                ]
            )
             
            output_parser = StrOutputParser()
            chain = prompt | st.session_state.llm | output_parser
            #stream = chain.stream(user_input,base64_image)
            stream = chain.stream({"user_input":user_input,"base64_image": base64_image})
            #print("stream=",stream)
            #response = chain.invoke(user_input)
            # LLMã®è¿”ç­”ã‚’è¡¨ç¤ºã™ã‚‹  Streaming
            with st.chat_message('ai'):   
                #st.write(response)  
                response =st.write_stream(stream) 
            #print("response=",response)            
        

        print(f"{st.session_state.model_name}=",response)
        

        # éŸ³å£°å‡ºåŠ›å‡¦ç†                
        if st.session_state.output_method == "éŸ³å£°":
            speak_thread = speak_async(response)
            # å¿…è¦ã«å¿œã˜ã¦éŸ³å£°åˆæˆã®å®Œäº†ã‚’å¾…ã¤
            speak_thread.join()    
            print("éŸ³å£°å†ç”ŸãŒå®Œäº†ã—ã¾ã—ãŸã€‚æ¬¡ã®å‡¦ç†ã‚’å®Ÿè¡Œã—ã¾ã™ã€‚")
        if engine._inLoop:
            print("éŸ³å£°å‡ºåŠ›ãŒLOOPã«ãªã£ã¦ã„ã¾ã™ã€‚")
            engine.endLoop()
            print("éŸ³å£°å†ç”ŸLOOPã‚’è§£é™¤ã—ã¾ã—ãŸã€‚æ¬¡ã®å‡¦ç†ã‚’å®Ÿè¡Œã§ãã¾ã™")

        # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã«è¿½åŠ 
        st.session_state.message_history.append(("user", user_input))
        st.session_state.message_history.append(("ai", response))
    
        return response
    except StopIteration:
        # StopIterationã®å‡¦ç†
        print("StopIterationãŒç™ºç”Ÿ")
        pass

    user_input = ""
    base64_image = ""
    frame = ""    
#######################################################################

class VideoTransformer(VideoTransformerBase):
    def __init__(self):
        self.frame = None

    def recv(self, frame):   
        self.frame = frame.to_ndarray(format="bgr24")
        return frame
#######################################################################
# éŸ³å£°å…¥åŠ›ï¼ˆèªè­˜ï¼‰é–¢æ•°
def speech_to_text():
    with sr.Microphone() as source:
        audio = r.listen(source)
        try:
            return r.recognize_google(audio, language="ja-JP")
        except:
            return ""
#######################################################################
#éŸ³å£°å‡ºåŠ›é–¢æ•°
def speak_async(text):
    def run():
        engine.say(text)
        engine.startLoop(False)
        engine.iterate()
        engine.endLoop()
    thread = threading.Thread(target=run)
    thread.start()
    return thread
####################################################################### 
####################################################################### 
#def main():
async def main():     
    ###################################################################    
    #ç”»é¢è¡¨ç¤º
    #streamlit.errors.StreamlitAPIException: `set_page_config()` can only be called once per app page, 
    # and must be called as the first Streamlit command in your script
    init_page()
    init_messages()
    # éŸ³å£°èªè­˜ã®è¨­å®š
    #recognizer = sr.Recognizer()
    # éŸ³å£°åˆæˆã®è¨­å®š
    #engine = pyttsx3.init()

    #stã§ä½¿ã†å¤‰æ•°åˆæœŸè¨­å®š
    st.session_state.llm = select_model()
    st.session_state.input_method = ""
    st.session_state.user_input = ""
    st.session_state.result = ""
    st.session_state.frame = "" 
    
    col, col2 = st.sidebar.columns(2)
     # å„åˆ—ã«ãƒœã‚¿ãƒ³ã‚’é…ç½®
    with col:
        # å…¥åŠ›æ–¹æ³•ã®é¸æŠ
        input_method = st.sidebar.radio("å…¥åŠ›æ–¹æ³•", ("ãƒ†ã‚­ã‚¹ãƒˆ", "éŸ³å£°"))
        st.session_state.input_method = input_method
     # å„åˆ—ã«ãƒœã‚¿ãƒ³ã‚’é…ç½®
    with col2:
        # å‡ºåŠ›æ–¹æ³•ã®é¸æŠ
        output_method = st.sidebar.radio("å‡ºåŠ›æ–¹æ³•", ("ãƒ†ã‚­ã‚¹ãƒˆ", "éŸ³å£°"))
        st.session_state.output_method = output_method

    # ãƒãƒ£ãƒƒãƒˆå±¥æ­´ã®è¡¨ç¤º (ç¬¬2ç« ã‹ã‚‰å°‘ã—ä½ç½®ãŒå¤‰æ›´ã«ãªã£ã¦ã„ã‚‹ã®ã§æ³¨æ„)
    for role, message in st.session_state.get("message_history", []):
        st.chat_message(role).markdown(message)
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«WebRTCã‚¹ãƒˆãƒªãƒ¼ãƒ ã‚’è¡¨ç¤º
    with st.sidebar:
        st.header("Webcam Stream")
        webrtc_ctx=webrtc_streamer(
                key="speech-to-text",
                desired_playing_state=True, 
                mode=WebRtcMode.SENDRECV,
                #audio_receiver_size=1024,
                rtc_configuration={"iceServers": [{"urls": ["stun:stun.l.google.com:19302"]}]},
                media_stream_constraints={"video": True, "audio": False},
                #audio_processor_factory=AudioTransformer,
                video_processor_factory=VideoTransformer,
            )   
                 
    
    ###################################################################        
    ###############################################################################
    #å…¥åŠ›ãƒ‡ãƒ¼ã‚¿è¨­å®š
    #ã‚­ãƒ£ãƒ—ãƒãƒ£ãƒ¼ç”»åƒå…¥åŠ›
    if webrtc_ctx.video_transformer:  
        frame = webrtc_ctx.video_transformer.frame  #VideoProcessor.frame 

    # ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ãƒ•ã‚©ãƒ¼ãƒ 
    if st.session_state.input_method == "ãƒ†ã‚­ã‚¹ãƒˆ":
        button_input = ""
        # 4ã¤ã®åˆ—ã‚’ä½œæˆ
        col1, col2, col3, col4 = st.columns(4)

        # å„åˆ—ã«ãƒœã‚¿ãƒ³ã‚’é…ç½®
        with col1:
            if st.button("ç”»åƒã®å†…å®¹ã‚’èª¬æ˜ã—ã¦"):
                button_input = "ç”»åƒã®å†…å®¹ã‚’èª¬æ˜ã—ã¦"

        with col2:
            if st.button("å‰ã®ç”»åƒã¨ä½•ãŒå¤‰ã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ"):
                button_input = "å‰ã®ç”»åƒã¨ä½•ãŒå¤‰ã‚ã‚Šã¾ã—ãŸã‹ï¼Ÿ"

        with col3:
            if st.button("çŸ³å·çœŒã®è¦³å…‰åœ°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"):
                button_input = "çŸ³å·çœŒã®è¦³å…‰åœ°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"

        with col4:
            if st.button("CIDPã¨ã¯ï¼Ÿ"):
                button_input = "CIDPã¨ã¯ï¼Ÿ"

        col5, col6, col7, col8 = st.columns(4)
        with col5:
            if st.button("æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"):
                button_input = "æ—¥æœ¬èªã«ç¿»è¨³ã—ã¦ãã ã•ã„ã€‚"


        with col6:
            if st.button("å–„æ‚ªã¯ä½•ã§æ±ºã¾ã‚Šã¾ã™ã‹ï¼Ÿ"):
                button_input = "å–„æ‚ªã¯ä½•ã§æ±ºã¾ã‚Šã¾ã™ã‹ï¼Ÿ"

        with col7:
            if st.button("æ—¥æœ¬ã®è¦³å…‰åœ°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"):
                button_input = "æ—¥æœ¬ã®è¦³å…‰åœ°ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚"

        with col8:
            if st.button("ä»Šæ—¥ã®æ–™ç†ã¯ãªã«ãŒã„ã„ã‹ãª"):
                button_input = "ä»Šæ—¥ã®æ–™ç†ã¯ãªã«ãŒã„ã„ã‹ãª"

        #query="""ä»¥ä¸‹ã®ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã‚¢ãƒ—ãƒªã®pythonã‚³ãƒ¼ãƒ‰ã‚’æ•™ãˆã¦ãã ã•ã„ã€‚
                #1.Streamlitã§Webè¡¨ç¤ºã™ã‚‹ã€‚
                #2.å¯èƒ½ãªé™ã‚Šlangchainãƒ©ã‚¤ãƒ–ãƒ©ãƒªã‚’ä½¿ç”¨ã—ã¦ãã ã•ã„ã€‚
                #3.ãƒãƒ«ãƒãƒœãƒ¼ãƒ€ãƒ«å¯¾å¿œã®LLMã‚’5ãƒ¢ãƒ‡ãƒ«ï¼ˆgpt-4o,claude3.5 sonnet,gemini-1.5-pro,command-r-plus,mistral)ã‹ã‚‰é¸æŠã—ã¦ä½¿ç”¨ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¨­å®šã™ã‚‹ã€‚
                #4.streamlit_webrtcã‚’ä½¿ç”¨ã—ã€å¸¸æ™‚Webã‚«ãƒ¡ãƒ©ç”»åƒã‚’è¡¨ç¤ºã—ã€ã‚«ãƒ¡ãƒ©ç”»åƒã«ã¤ã„ã¦å•ã„åˆã‚ã›ã‚‚ã§ãã‚‹ã‚ˆã†ã«ã™ã‚‹ã€‚
                #5.LLMã¸ã®å•ã„åˆã‚ã›å…¥åŠ›ã‚’ã‚­ãƒ¼ãƒœãƒ¼ãƒ‰ã«ã‚ˆã‚‹ãƒ†ã‚­ã‚¹ãƒˆå…¥åŠ›ã®å ´åˆã¨éŸ³å£°å…¥åŠ›ã®å ´åˆã‚’é¸æŠã—ã¦ä½¿ç”¨ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¨­å®šã™ã‚‹ã€‚
                #6.LLMã¸å•ã„åˆã‚ã›å…¥åŠ›ã™ã‚‹éš›ã¯ã€Webã‚«ãƒ¡ãƒ©ã®ã‚­ãƒ£ãƒ—ãƒãƒ£ç”»åƒã‚‚å…¥åŠ›ã™ã‚‹ã€‚
                #7.LLMã‹ã‚‰ã®å‡ºåŠ›ã‚’ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã®ã¿ã™ã‚‹å ´åˆã¨ãƒ†ã‚­ã‚¹ãƒˆå‡ºåŠ›ã¨éŸ³å£°å‡ºåŠ›ã®ä¸¡æ–¹å‡ºåŠ›ã™ã‚‹å ´åˆã¨ã‚’é¸æŠã—ã¦ä½¿ç”¨ã™ã‚‹ãƒœã‚¿ãƒ³ã‚’è¨­å®šã™ã‚‹ã€‚
                #8.éŸ³å£°å‡ºåŠ›ã€LLMã¸ã®å•ã„åˆã‚ã›å¿œç­”ãªã©éåŒæœŸå‡¦ç†ã«ã™ã‚‹å¿…è¦ãŒã‚ã‚‹ã‹ã‚‚ã—ã‚Œã¾ã›ã‚“ã€‚
                #streamlit_webrtã‚’ä½¿ç”¨ã—ã€LLMã«éŸ³å£°ã€ç”»åƒã€ãƒ†ã‚­ã‚¹ãƒˆã‚’å…¥åŠ›ã—ã¦ãƒ†ã‚­ã‚¹ãƒˆã¨éŸ³å£°ã§å‡ºåŠ›ã™ã‚‹ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆã®ã‚³ãƒ¼ãƒ‰ã‚’æ•™ãˆã¦"""
        #if st.button(query):
                #button_input = query
          
        if button_input !="":
            st.session_state.user_input=button_input
        
        # ã‚¯ãƒªã‚¢ãƒœã‚¿ãƒ³ãŒæŠ¼ã•ã‚ŒãŸå ´åˆã€ã‚»ãƒƒã‚·ãƒ§ãƒ³ã‚¹ãƒ†ãƒ¼ãƒˆã®å€¤ã‚’ã‚¯ãƒªã‚¢
        #Streamlitã®st.text_input()ã§ä»¥å‰å…¥åŠ›ã—ãŸãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢ã™ã‚‹ã«ã¯ã€keyå¼•æ•°ã‚’å‹•çš„ã«å¤‰æ›´ã™ã‚‹æ–¹æ³•ãŒåŠ¹æœçš„ã§ã™ã€‚
        #ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã™ã‚‹ãŸã³ã«text_inputã®keyãŒå¤‰æ›´ã•ã‚Œã€å…¥åŠ›ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ãŒãƒªã‚»ãƒƒãƒˆã•ã‚Œã¾ã™ã€‚
        # ã“ã‚Œã¯ã€Streamlitã®å†å®Ÿè¡Œã®ä»•çµ„ã¿ã‚’åˆ©ç”¨ã—ã¦å…¥åŠ›ã‚’ã‚¯ãƒªã‚¢ã™ã‚‹åŠ¹æœçš„ãªæ–¹æ³•ã§ã™ã€‚
        #if 'text_input' not in st.session_state:
            #st.session_state.text_input = random.randint(1, 100000)
        #if st.button("å‰ã®ãƒ†ã‚­ã‚¹ãƒˆã‚’ã‚¯ãƒªã‚¢"):
            #clear_text()
        
        text_input =st.chat_input("ãƒ†ã‚­ã‚¹ãƒˆã§å•ã„åˆã‚ã›ã‚‹å ´åˆã€ã“ã“ã«å…¥åŠ›ã—ã¦ã­ï¼") #,key=st.session_state.text_input)
        #text_input = st.text_input("ãƒ†ã‚­ã‚¹ãƒˆã§å•ã„åˆã‚ã›ã‚‹å ´åˆã€ä»¥ä¸‹ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ã«å…¥åŠ›ã—ã¦ãã ã•ã„:", key=st.session_state.text_input) 
        if text_input:
            st.session_state.user_input=text_input
            text_input=""

        if st.session_state.user_input:
            print("user_input=",st.session_state.user_input)
            with st.chat_message('user'):   
                st.write(st.session_state.user_input) 
        # å¯¾è©±ãƒ«ãƒ¼ãƒ— 
        # ç”»åƒã¨å•ã„åˆã‚ã›å…¥åŠ›ãŒã‚ã£ãŸã¨ãã®å‡¦ç†
            if frame is not None and st.session_state.user_input !="":
                st.sidebar.header("Capture Image")
                st.sidebar.image(frame, channels="BGR")
                # if st.button("Query LLM : ç”»åƒã®å†…å®¹ã‚’èª¬æ˜ã—ã¦"):
                with st.spinner("Querying LLM..."):
                    loop = asyncio.new_event_loop()
                    asyncio.set_event_loop(loop)
                    st.session_state.result= ""
                    result = loop.run_until_complete(query_llm(st.session_state.user_input,frame))
                    st.session_state.result = result
                    result = ""
                    #result = await query_llm(text,frame)
                    st.session_state.user_input=""

    ###############################################################################
    #éŸ³å£°å…¥åŠ›ï¼ˆãƒ†ã‚­ã‚¹ãƒˆã«å¤‰æ›ã—ãŸå…¥åŠ›ï¼‰ã®å¯¾è©±ãƒ«ãƒ¼ãƒ—
    #print("Before_st.session_state.input_method=",st.session_state.input_method)
    if st.session_state.input_method == "éŸ³å£°": 
        already_displayed = False
        st.sidebar.header("Capture Image") 
        image_placeholder = st.sidebar.empty()
         
        while True:
            if not already_displayed:
                print("è©±ã—ã‹ã‘ã¦ãã ã•ã„...")
                st.write("ğŸ¤—è©±ã—ã‹ã‘ã¦ãã ã•ã„...")
                already_displayed = True
            st.session_state.user_input = ""
            st.session_state.user_input = speech_to_text()
            if keyboard.is_pressed('1') :st.session_state.user_input ="ã“ã‚“ã°ã‚“ã¯"
            if keyboard.is_pressed('2') :st.session_state.user_input ="ç”»åƒã®å†…å®¹ã‚’èª¬æ˜ã—ã¦"
            if keyboard.is_pressed('3') :st.session_state.user_input ="çŸ³å·çœŒå°æ¾å¸‚ã®è¦³å…‰åœ°ã¯ï¼Ÿ"
            if keyboard.is_pressed('4') :st.session_state.user_input ="æœ‰åãªé“ã®é§…ã¯ï¼Ÿ"
            if keyboard.is_pressed('5') :st.session_state.user_input ="CIDPã¨ã¯ï¼Ÿ"
            if keyboard.is_pressed('6') :st.session_state.user_input ="ãã‚‡ã†ã®æ–™ç†ã¯ãªã«ãŒã„ã„ã‹ãª"
            if keyboard.is_pressed('7') :st.session_state.user_input ="å®‡å®™äººã¯ã„ã¾ã™ã‹ï¼Ÿ"
            if keyboard.is_pressed('8') :st.session_state.user_input ="ç§ã®åå‰ã¯èª ã§ã™ã€‚"
            if keyboard.is_pressed('9') :st.session_state.user_input ="ç§ã®åå‰ã¯ï¼Ÿ"
            if keyboard.is_pressed('9') :st.session_state.user_input ="å–„æ‚ªã¯ä½•ã§æ±ºã¾ã‚Šã¾ã™ã‹ï¼Ÿ"
            if keyboard.is_pressed('esc') :
                print("éŸ³å£°ã§ã®å•ã„åˆã‚ã›ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚")
                with st.chat_message('assistant'):   
                    st.write("éŸ³å£°ã§ã®å•ã„åˆã‚ã›ã‚’çµ‚äº†ã—ã¾ã—ãŸã€‚") 
                #break   
            # å¯¾è©±ãƒ«ãƒ¼ãƒ— 
            # ç”»åƒã¨å•ã„åˆã‚ã›å…¥åŠ›ãŒã‚ã£ãŸã¨ãã®å‡¦ç†
            if webrtc_ctx.video_transformer: #VideoProcessor
                frame = webrtc_ctx.video_transformer.frame  #VideoProcessor.frame 
            if frame is not None and st.session_state.user_input !="":
                #ã‚µã‚¤ãƒ‰ãƒãƒ¼ã«ç”»åƒã‚’è¡¨ç¤º
                image_placeholder.image(frame, channels="BGR")
                #ãƒ¦ãƒ¼ã‚¶ãƒ¼ã®éŸ³å£°å…¥åŠ›ã‚’è¡¨ç¤º
                with st.chat_message('user'):   
                    st.write(st.session_state.user_input) 
                #LMMã®å›ç­”ã‚’è¡¨ç¤º 
                with st.spinner("Querying LLM..."):
                    #loop = asyncio.new_event_loop()
                    #asyncio.set_event_loop(loop)
                    #st.session_state.result= ""
                    #result = loop.run_until_complete(query_llm(st.session_state.user_input,frame))
                    result = await query_llm(st.session_state.user_input,frame)
                st.session_state.result = result
                result = ""
                st.session_state.user_input=""
                already_displayed = False
                    
    ###############################################################################  
    ###############################################################################
    #print("after_st.session_state.input_method=",st.session_state.input_method)

if __name__ == "__main__":
    #main()
    #asyncio.run(main())
    loop = asyncio.get_event_loop()
    loop.run_until_complete(main())
